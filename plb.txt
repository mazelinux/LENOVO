C2pbrakf
repo init -b intelCHT_M_MR1_dev -u tablet:/platform/manifest
repo init Cu sma:platform/manifest Cb intelCHT_M_MR1_dev

Q：热插拔。软件+硬件、、。。。。


A：一个完整的热插拔系统包括热插拔系统的硬件，支持热插拔的软件和操作系统，支持热插拔的设备驱动程序和支持热插拔的用户接口。
硬件支持：插入，先数据，后电源；拔出，先电源，后数据
uevent, user space event. 内核与用户空间的一种通信机制

http://www.wowotech.net/linux_kenrel/uevent.html 主要讲述的是头文件
热插拔事件从内核空间到用户空间

/// http://blog.csdn.net/bingqingsuimeng/article/details/7922217 一般，并且知识体系太老了

http://blog.csdn.net/bingqingsuimeng/article/details/7924300  有源代码的讲解，比较清晰

http://www.cnblogs.com/image-eye/archive/2011/08/19/2145858.html 内核启动过程的驱动加载

http://blog.chinaunix.net/uid-25721104-id-3023525.html 讨论的关于热插拔

http://blog.csdn.net/zirconsdu/article/details/8792184 图解很清晰

讲清楚了koject_uevent_env在做了什么，如何进入用户空间
如果定义了"CONFIG_NET”，则使用netlink发送该uevent
其中的call_usermodehelper是个最终切换接口

Uevent模块准备好上报事件的格式后，可以通过两个途径把事件上报到用户空间：一种是通过kmod模块，直接调用用户空间的可执行文件；另一种是通过netlink通信机制，将事件从内核空间传递给用户空间。//这里的kmod是什么鬼？
而在Linux系统，可执行文件的执行，依赖于环境变量，因此kobj_uevent_env用于组织此次事件上报时的环境变量。

软件支持：插入设备->device_add->kobject_uevent->kobject_uevent_env（之前都是内核空间动作）->call_usermodehelper_setup->call_usermodehelper_exec->调用用户空间应用(call_usermodehelper=setup+exec)，

http://blog.chinaunix.net/uid-27666459-id-5747129.html讲解 call_usermodehelper

udevd (udev 后台程序)

1 外设插入
2 总线发现（usb中断hub_irq）新设备，调用device_add;添加新设备到设备管理器
3 device_add调用kobject_uevent(,KOBJ_ADD),向用户空间传递环境变量以及action；netlink方式（广播方式）【主要就是Uevent】
4 用户空间应用程序收到消息【udev ->> udevd】
5 udevd根据消息和环境变量，查询/sys的变化，按照规则(/etc/udev/rules.d/*)，在/dev目录下自动创建设备节点；


同时可以总结，设备插入系统时，相应驱动的关联情况：
① 若直接编译进内核或在启动时加载，则无需在udev中加载驱动模块，在bus_probe_device()中会为其找到相应的驱动；
② 若驱动需要动态加载，则需要在udev(目前的情况是这样，以前也有其他方式如/sbin/hotplug，cardmgr等)中，动态加载其驱动，在驱动的register函数中，找到该device进行关联；

udev 是Linux kernel 2.6系列的设备管理器，它主要的功能是管理/dev目录底下的设备节点的程序。
udevd是根据一定的规则在/dev/目录下生成设备文件的后台服务进程。

比如你插入一个u盘， udevd服务就会自动生成/dev/sda 这样的文件。
=======================================================================
=======================================================================
http://eeepage.info/sysfs/ 对新的sysfs的讲解非常到位
http://www.linuxidc.com/Linux/2012-05/60757.htm 同样讲解sysfs文件系统
http://blog.chinaunix.net/uid-24227137-id-3266449.html 讲解kobject,kset,sysfs
=======================================
从面向对象的角度来看： 
    - struct kobj（及其相关结构如kset, ktype等）属于最抽象的基类，代码最简洁，最不具体； 
    - struct device（及其相关结构如device_driver，device_type等）是对kobj的封装，是第一层派生类； 
    - 再上层的结构（如platform_device等），是在struct device的基础上再封装一次，是第二层派生类。 

因此，例如我们创建了一个struct platform_device的实例，使用完毕后要释放它。那么这个过程按道理应该是： 
    - 系统内部先调用platform_device的remove函数，它只处理自己层特有的变量； 
    - 完毕后，系统调用第一层派生类struct device的release函数，处理了自己这一层的特有变量； 
    - 最后，调用基类kobject的release函数，将整个空间释放掉。 

整个过程应该会跟C++析构过程比较类似，上述的“系统内部”也应该类似于C++编译器自动生成的代码，因为C++中析构函数的逆向调用是自动进行的，并没有在派生类的析构函数中显示调用。类似地，在此处上层的release中也不会显式调用下层的release，都是由系统内部完成的。 
========================================
=======================================================================
=======================================================================


Q:最小子系统，，，。。。。+ramdisk+initrd 在深入

A:
ramdisk是一种基于内存的虚拟文件系统，通常用于放置内核的中间数据。
而initrd全称为"boot loader initialized RAM disk"，也就是由启动加载器所初始化的RamDisk设备，它的作用是完善内核的模块机制，让内核的初始化流程更具弹性；内核以及initrd，都由bootloader在机子启动后被加载至内存的指定位置，主要功能为按需加载模块以及按需改变根文件系统。

initrd 的英文含义是 bootloader initialized RAM disk，就是由 boot loader 初始化的内存盘。
initrd 大体上就是指 包含根文件系统的ramdisk。
initrd即initial ramdisk,它是在系统引导过程中挂载的一个临时根文件系统.激活系统所须加载的文件系统.

http://blog.chinaunix.net/uid-23069658-id-3142047.html  Linux系统启动全过程
http://blog.sina.com.cn/s/blog_c70e10380102w9b5.html     Linux系统启动全过程，详细，方便理解

总结：

================================================
BIOS(Basic Input Output System) 
包括

    自检及初始化
POST上电自检（如果内存没有插好，开机会滴滴的响，这就是上电自检查处了问题）

初始化
系统设置程序（开机按f2或者f12跳出来的配置界面就是配置这个参数）：：：准确的说法应是通过BIOS设置程序对CMOS参数进行设置

引导程序
将系统控制权给引导记录

    程序服务处理
    硬件中断处理


http://baike.baidu.com/link?url=_tfzs1c0Le4haxojK1eUqipL33Wwv2HTYQBnCypCO2FtIiHOI8p6m9fwQUi51vsH4P_m0zlGydj4WNLdkCsfA_
===================================================

===================================================
系统引导
最终 boot loader 的功能就是加载 kernel（内核）文件。
===================================================

===================================================
启动内核
虚拟文件系统 (Initial RAM Disk) 一般使用的文件名为 /boot/initrd ，
这个文件的特色是，它也能够通过boot loader 来加载到内存中， 然后这个文件会被解压缩并且在内存当中仿真成一个根目录，
且此仿真在内存当中的文件系统能够提供一个可执行的程序，通过该程序来加载启动过程中所最需要的内核模块，通常这些模块就是 U盘, RAID, LVM, SCSI 等文件系统与磁盘接口的驱动程序。
等载入完成后，会帮助内核重新调用 /sbin/init 来开始后续的正常启动流程

http://blog.sina.com.cn/s/blog_c70e10380102w9b5.html
====================================================

http://photo.blog.sina.com.cn/showpic.html#blogid=c70e10380102w9b5&url=http://album.sina.com.cn/pic/003E0ziMty71l8BWmO5b9 一张图片关于bios以后的bootloader 这张图片 讲解的非常详细
http://blog.csdn.net/miss_acha/article/details/50004717 讲述的不错关于grub
http://www.2cto.com/os/201603/494064.html后半段讲的很清楚

http://www.ibm.com/developerworks/cn/views/linux/libraryview.jsp?sort_by=&show_abstract=true&show_all=&search_flag=&contentarea_by=Linux&search_by=initrd&topic_by=-1&type_by=%E6%89%80%E6%9C%89%E7%B1%BB%E5%88%AB&ibm-search=%E6%90%9C%E7%B4%A2
IBM提供的文档库里面比较全


先后出现两种机制来作为“boot loader装载kernel”到“真正的/sbin/init执行”这个启动过程的桥梁: initrd和initramfs  


ramdisk==ramtodisk
initrd==init ramdisk

内核在启动的时候，需要加载一些驱动，需要一些内核模块，没有文件系统，就没有文件
文件系统在哪里？在硬盘上实现的，没有硬盘~所以使用ramdisk技术，把内存的一块区域模拟成硬盘使用，initrd将这块“硬盘”初始化，加载必要的文件系统，这个initrd是一个压缩文件系统，里面有一些必要的应用程序以及模块等等，辅助内核完成内核的初始化
initrd基本解压以后就暂时的挂载在根目录下面，然后内核就把他当作根目录来执行一些必要的任务，加载模块等等，后期再将他挂载到一个其他的目录，从而挂载真正的根目录


我的虚拟机里面有解压好的initrd压缩文件；经过观察，基本就是一个空的文件系统+一个init的脚本，这个脚本的内容：1创建相应的目录，并且挂载相应的文件系统。创建一些设备节点，随后指定一些变量的值，如 init，root等等
Q：一般什么是.ko
A:
.so 文件是动态链接库文件，相当于 win下的 .dll 文件。
.a  文件是静态库文件。
.ko 是内核模块文件，是内核加载的某个模块，一般是驱动程序。


Q：什么样的设备挂在在paltform上

A:所有的设备都可以挂载在platform上

http://blog.chinaunix.net/uid-25014876-id-111745.html 讲解platform总线的
设备注册的流程

platform_device_register->device_initialize->device_add->setup_parent->kobject_add->device_create_file->device_add_attrs->bus_add_device->kobject_uevent->bus_attach_device
gpio通过platform实现


Q:
tasklet
schedule
isr
关系

前三者的联系在于中断子系统


tasklet
http://www.kuqin.com/shuoit/20140104/337421.html 讲述了什么是tasklet
http://blog.csdn.net/lizuobin2/article/details/51793911 这篇讲的比较好，把中断对应的机制分的很详细；但是只是做了一个详细的划分，机制原理讲述不清
同一个tasklet不能同时在多个cpu上跑

DECLARE_TASKLET（my_tasklet,my_tasklet_func,data）

schedule
http://blog.csdn.net/songjinshi/article/details/23262923 讲述调用调度程序的时机

每个时钟中断（timer interrupt）发生时，由三个函数协同工作，共同完成进程的选择和切换，它们是：schedule（）、do_timer（）及ret_form_sys_call（）。我们先来解释一下这三个函数：
schedule（）：进程调度函数，由它来完成进程的选择（调度）；
do_timer（）：暂且称之为时钟函数，该函数在时钟中断服务程序中被调用，是时钟中断服务程序的主要组成部分，该函数被调用的频率就是时钟中断的频率即每秒钟100次（简称100赫兹或100Hz）；
ret_from_sys_call（）：系统调用返回函数。当一个系统调用或中断完成时，该函数被调用，用于处理一些收尾工作，例如信号处理、核心任务等等。

isr：中断服务程序 ISR(Inerrupt Service Routine)

简单来说就是，一条中断线对应一个中断处理程序，而一个中断处理程序再对应若干个中断服务例程 ：http://blog.chinaunix.net/uid-27177626-id-3438994.html
图解加文字叙述，比较容易理解

http://blog.sina.com.cn/s/blog_70a9dd840100uqfh.html 讲述了什么是isr，也涉及了中断上下文以及中断上半部和下半部
http://blog.sina.com.cn/s/blog_65373f1401018w15.html
http://blog.sina.com.cn/s/blog_510ac74901015fgz.html

http://blog.csdn.net/DroidPhone/article/details/7445825 中断子系统的一系列文章

http://blog.csdn.net/lickylin/article/details/12657373 总结依托于这篇文章写

总结：tasklet是一种基于软中断的延时处理机制，是中断底半部的一种处理方式。
基本上要使用就是申请中断，通过宏创建tasklet与处理函数的关联，在顶半部调用tasklet_schedule使系统在适当的时候进行调
（就是把tasklet_struct结构体挂到tasklet_vec链表或者挂接到tasklet_hi_vec链表上，并调度软中断TASKLET_SOFTIRQ或者HI_SOFTIRQ；Tasklet_action在软中断TASKLET_SOFTIRQ被调度到后会被执行，它从tasklet_vec链表中把tasklet_struct结构体都取下来，然后逐个执行。如果t->count的值等于0，说明这个tasklet在调度之后，被disable掉了，所以会将tasklet结构体重新放回到tasklet_vec链表，并重新调度TASKLET_SOFTIRQ软中断，在之后enable这个tasklet之后重新再执行它。）；
======================================================================
上半部和下半部的关键区别是，上半部简单快速，执行时禁止一部分或者全部中断；下半部稍后执行，而且执行期间可以响应所有中断。
======================================================================
上半部和下半部的划分可以参考以下原则：
1) 如果一个任务对时间非常敏感，把它放在上半部（ISR）里；
2) 如果一个任务跟硬件相关，把它放在上半部里；
3) 如果一个任务要保证不被其他中断（特别是相同的中断）打断，把它放在上半部里；
4) 其他所有的任务，都放在下半部。
======================================================================
下半部负责推后完成的工作，但是并不需要指明一个具体的时间，只是将任务稍微推迟，待到系统不是那么繁忙并且中断恢复之后执行就可以了（一般情况下，ISR一返回，下半部就会执行）。不同于ISR的最关键之处是，下半部执行的时候允许响应所有的中断。
======================================================================
内核的策略是，当中断不是特别多的时候，及时处理中断，所以do_irq会调用do_softirq。
当系统中断过多时，do_softirq才会被推迟到内核的ksoftirq内核线程中去。如何判断中断过多呢，linux的认为发生中断嵌套了，就是中断过多。do_irq在调用do_softirq时会以此为判断条件。
======================================================================
__tasklet_schedule：
作用：
1、 关闭中断
2、 调用__tasklet_common_schedule，实现添加tasklet并开启软中断的功能
3、 开启中断

tasklet_schedule
__tasklet_schedule
__tasklet_common_schedule

3个函数实现了将tasklet添加到tasklet_vec（每个CPU都有一个该变量）中，并开启软中断。

tasklet_action：
作用：
1） 关闭软中断，获取运行CPU所对应的tasklet链表的表头，然后将表头置为NULL，再启中断
2） 遍历tasklet链表，每次遍历均执行如下操作：
a) 获取tasklet链表的一个tasklet变量
b) 对该tasklet执行加锁操作，即置位TASKLET_STATE_RUN
c) 判断当前tasklet是否使能，若已使能，则执行以下操作
i. tasklet的当前状态若为TASKLET_STATE_SCHED，则清空该位
ii. 调用该tasklet的回调处理函数
iii. 解锁该tasklet，重新while循环
若未使能，则执行以下操作：
i. 关闭中断
ii. 将该tasklet重新加入到链表tasklet_vec
iii. 开启软中断TASKLET_SOFTIRQ，在 下一次处理该软中断时，再处理该tasklet
iv. 开启中断

底半部机制包括:tasklet，工作队列，软中断，线程中断；



Q:锁的概念 三种，
Q:锁的概念
http://blog.csdn.net/lucien_cc/article/details/7440225
mutex(互斥锁)
Spanlock(自旋锁)
atomic（原子操作）
semaphore (信号量)
rw_semaphore （读写信号量）
seqlock（顺序锁）
rm_lock (读写自旋锁)
completion（完成量）


自旋锁用于临界区小的情况；互斥用于临界区大的情况

Q:文件描述符

Q:块设备完成了以后传给谁

Q:设备驱动读出来以后传给谁


Q:设备驱动跑起来的第一个函数是哪一个！
A:module__init
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Q:input_device+*pdevice 关系
Q:Input子系统架构
http://blog.csdn.net/lbmygf/article/details/7360084
http://blog.chinaunix.net/uid-20776117-id-3212043.html

Q：MODULE_DEVICE_TABLE是个什么东西？
MODULE_DEVICE_TABLE（设备类型，设备表），其中，设备类型，包括USB,PCI等，也可以自己起名字，上述代码中是针对不同的平台分的类；设备表也是自己定义的，它的最后一项必须是空，用来标识结束。



Q:一个I2C总线只能有一个配适器？如何实现传输
http://blog.csdn.net/zclongembedded/article/details/8255977详解传输

Q:私有结构体到底是个什么概念？

Q:输入子系统（input）如何与i2c关联起来的？

Q:msleep() 与mdelay()
http://blog.csdn.net/mayouyang/article/details/4228378 两者实际运用区别


Q:initcall的执行先后顺序
#define module_init(x)    	__initcall(x);

#define __initcall(fn) 		device_initcall(fn)

#define device_initcall(fn)	__define_initcall("6",fn,6)

执行顺序表：
=======================================================================
core_init被放在第1时间, arch_initcall被放在第3时间,  fs_initcall被放在第5时间. 这些在kernel-3.0/include/linux/init.h中定义
=======================================================================
#define pure_initcall(fn)          __define_initcall("0",fn,0)

#define core_initcall(fn)          __define_initcall("1",fn,1)

#define core_initcall_sync(fn)        __define_initcall("1s",fn,1s)

#define postcore_initcall(fn)           __define_initcall("2",fn,2)

#define postcore_initcall_sync(fn) __define_initcall("2s",fn,2s)

#define arch_initcall(fn)          __define_initcall("3",fn,3)

#define arch_initcall_sync(fn)        __define_initcall("3s",fn,3s)

#define subsys_initcall(fn)              __define_initcall("4",fn,4)

#define subsys_initcall_sync(fn)    __define_initcall("4s",fn,4s)

#define fs_initcall(fn)                     __define_initcall("5",fn,5)

#define fs_initcall_sync(fn)            __define_initcall("5s",fn,5s)

#define rootfs_initcall(fn)       __define_initcall("rootfs",fn,rootfs)

#define device_initcall(fn)              __define_initcall("6",fn,6)

#define device_initcall_sync(fn)    __define_initcall("6s",fn,6s)

#define late_initcall(fn)           __define_initcall("7",fn,7)

#define late_initcall_sync(fn)         __define_initcall("7s",fn,7s)
=======================================================================


Q:i2c关于bus-number与adapter的关系

你的开发板上有几个I2C接口，就有几个adapter , 也就是有几条I2C bus ，  I2C CLIENT 对应的就是你的外围I2C 设备，有几个就有几个CLIENT , 把这些设备插入开发板， 对应其中的一条BUS, 那么相应的就对应了其中的一个ADAPTER , 接下来的就是  CLIENT 与 ADAPTER 勾搭成对了， 后面就是做该做的事了

http://www.cnblogs.com/BitArt/archive/2013/05/27/3101037.html这篇文件对硬件讲解比较详细

http://blog.csdn.net/bob_fly1984/article/details/22690381根据实例讲解i2c

=======================================================================
Q:Kmalloc的特点
http://blog.sina.com.cn/s/blog_6648c11401011ho1.html
Q:函数request_threaded_irq( )
http://blog.chinaunix.net/uid-12461657-id-3064012.html
=======================================================================
为什么要提出中断线程化?
在 Linux 中，中断具有最高的优先级。不论在任何时刻，只要产生中断事件，内核将立即执行相应的中断
处理程序，等到所有挂起的中断和软中断处理完毕后才能执行正常的任务，
因此有可能造成实时任务得不
到及时的处理。中断线程化之后，中断将作为内核线程运行而且被赋予不同的实时优先级，实时任务可以
有比中断线程更高的优先级。这样，具有最高优先级的实时任务就能得到优先处理，即使在严重负载下仍
有实时性保证。but,并不是所有的中断都可以被线程化，比如时钟中断，主要用来维护系统时间以及定时器
等，其中定时器是操作系统的脉搏，一旦被线程化，就有可能被挂起，这样后果将不堪设想，所以不应当
被线程化。 

主要关键字 实时性。线程化中断
=======================================================================
当外设触发一次中断后，一个大概的处理过程是：
1、具体CPU architecture相关的模块会进行现场保护，然后调用machine driver对应的中断处理handler
2、machine driver对应的中断处理handler中会根据硬件的信息获取HW interrupt ID，并且通过irq domain模块翻译成IRQ number
3、调用该IRQ number对应的high level irq event handler，在这个high level的handler中，会通过和interupt controller交互，进行中断处理的flow control（处理中断的嵌套、抢占等），当然最终会遍历该中断描述符的IRQ action list，调用外设的specific handler来处理该中断
4、具体CPU architecture相关的模块会进行现场恢复。
上面的1、4这两个步骤在linux kernel的中断子系统之（六）：ARM中断处理过程中已经有了较为细致的描述，步骤2在linux kernel的中断子系统之（二）：irq domain介绍中介绍，本文主要描述步骤3，也就是linux中断子系统的high level irq event handler。
=======================================================================
=======================================================================
flags:与中断相关的标志   
IRQF_TRIGGER_RISING：上升沿触发  
IRQF_TRIGGER_FALLING：下降沿触发  
IRQF_TRIGGER_HIGH：高电平触发  
IRQF_TRIGGER_LOW：低电平触发   
IRQF_SAMPLE_RANDOM：为系统随机发生器提供支持  
IRQF_SHARED：中断可在设备间共享  
IRQF_DISABLED：是否快速中断
IRQF_ONESHOT:选项说明该中断已经被线程化了（而且是特殊的one shot类型的）
（虽然kernel的注释上是这样说，但是request_threaded_irq时还是必须要设定IRQF_ONESHOT，否者它就会被错误的强制线程化了。 
其实我觉得这个ONESHOT的命名也是很不好，它不仅仅表示one shot，而且还是thread irq的标志。）
=======================================================================http://blog.csdn.net/lengyuex/article/details/6272445这个跟看touchscreen一样

http://www.wowotech.net/irq_subsystem/request_threaded_irq.html



=======================================================================
Q:中断系统相关硬件描述
中断硬件系统主要有三种器件参与，各个外设、中断控制器和CPU
=======================================================================
struct irq_desc irq_desc[NR_IRQS] __cacheline_aligned_in_smp = { 
    [0 ... NR_IRQS-1] = { 
        .handle_irq    = handle_bad_irq, 
        .depth        = 1, 
        .lock        = __RAW_SPIN_LOCK_UNLOCKED(irq_desc->lock), 
    } 
};
系统中每一个连接外设的中断线（irq request line）用一个中断描述符来描述，每一个外设的interrupt request line分配一个中断号（irq number），系统中有多少个中断线（或者叫做中断源）就有多少个中断描述符（struct irq_desc）。NR_IRQS定义了该硬件平台IRQ的最大数目。
=======================================================================
有过这样的需求request_irq的时候并不想中断函数被立即调用。所以我一般情况是，在request-irq之前，先disable-irq。请问这样可以吗？我看过源代码，没有发现可能引起异常的部分。
wowo 
2015-03-09 16:18
@heziq：request IRQ和hardware enable，应该是两个逻辑，只有hardware enable了，才有可能产生中断。因此一般的做法是：在probe中request IRQ，在需要使用设备时，enable它，中断产生。
=======================================================================
有个小疑问，对于中断只简单使用过gpio中断，有个gpio_to_irq的函数，可以把gpio直接转换成 
request_irq函数中所需要的irq number， 而其它的中断，对于request_irq中的irq number号如何 
得到。=======================================================================
定义i2c从设备的时候：
I2C_BOARD_INFO("ov564x", 0x3c)
上面红色标注的8位从地址，最后一位是不是0或1都行

i2c协议里面最后一位是读写标志位.....I2C_BOARD_INFO只是说明地址......
=======================================================================
新的中断子系统的思路是将中断处理分成primary handler和threaded handler，而旧的驱动代码一般是将中断处理分成top half和bottom half，如何将这部分的不同抹平？
TODO
=======================================================================
http://blog.csdn.net/fanqipin/article/details/8153053 关于匹配讲述的很详细；如果关于驱动与设备的匹配出了问题，可以仔细看看
=======================================================================
等待队列wait_queue_head_t与完成量completion
http://blog.csdn.net/younger_china/article/details/7176851 详解
=======================================================================
request-thread-irq
等待队列处理特点
input子系统